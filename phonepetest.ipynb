{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_insurance\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "path1 = \"C://Users//aashi//Desktop//YoutubeProject//Phonepe//pulse//data//aggregated//insurance/country/india//state//\"\n",
    "agg_insur_list = os.listdir(path1)\n",
    "\n",
    "columns1 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Transaction_type\": [], \"Transaction_count\": [],\n",
    "            \"Transaction_amount\": []}\n",
    "\n",
    "for state in agg_insur_list:\n",
    "    cur_states = path1 + state + \"//\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year = cur_states + year + \"//\"\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file = cur_year + file\n",
    "            with open(cur_file, \"r\") as data:\n",
    "                A = json.load(data)\n",
    "\n",
    "                for i in A[\"data\"][\"transactionData\"]:\n",
    "                    name = i[\"name\"]\n",
    "                    count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                    amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                    columns1[\"Transaction_type\"].append(name)\n",
    "                    columns1[\"Transaction_count\"].append(count)\n",
    "                    columns1[\"Transaction_amount\"].append(amount)\n",
    "                    columns1[\"States\"].append(state)\n",
    "                    columns1[\"Years\"].append(year)\n",
    "                    columns1[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "aggre_insurance=pd.DataFrame(columns1) \n",
    "\n",
    "aggre_insurance[\"States\"]=aggre_insurance[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar' )\n",
    "aggre_insurance[\"States\"]=aggre_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_insurance[\"States\"]=aggre_insurance[\"States\"].str.title()\n",
    "aggre_insurance[\"States\"]=aggre_insurance[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggre_insurance[\"States\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggre_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_transaction\n",
    "\n",
    "path2 = \"C://Users//aashi//Desktop//YoutubeProject//Phonepe//pulse//data//aggregated//transaction//country//india//state//\"\n",
    "agg_tran_list = os.listdir(path2)\n",
    "\n",
    "columns2 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Transaction_type\": [], \"Transaction_count\": [],\n",
    "            \"Transaction_amount\": []}\n",
    "\n",
    "for state in agg_tran_list:\n",
    "    cur_states = path2 + state + \"//\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year = cur_states + year + \"//\"\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file = cur_year + file\n",
    "            with open(cur_file, \"r\") as data:\n",
    "                B = json.load(data)\n",
    "\n",
    "                for i in B[\"data\"][\"transactionData\"]:\n",
    "                    name = i[\"name\"]\n",
    "                    count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                    amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                    columns2[\"Transaction_type\"].append(name)\n",
    "                    columns2[\"Transaction_count\"].append(count)\n",
    "                    columns2[\"Transaction_amount\"].append(amount)\n",
    "                    columns2[\"States\"].append(state)\n",
    "                    columns2[\"Years\"].append(year)\n",
    "                    columns2[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "aggre_transaction=pd.DataFrame(columns2)\n",
    "\n",
    "aggre_transaction[\"States\"]=aggre_transaction[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar' )\n",
    "aggre_transaction[\"States\"]=aggre_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_transaction[\"States\"]=aggre_transaction[\"States\"].str.title()\n",
    "aggre_transaction[\"States\"]=aggre_transaction[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggre_transaction[\"States\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggre_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_user\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "path3 = \"C://Users//aashi//Desktop//YoutubeProject//Phonepe//pulse//data//aggregated//user//country//india//state//\"\n",
    "agg_user_list = os.listdir(path3)\n",
    "\n",
    "columns3 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Brands\": [], \"Transaction_count\": [], \"Percentage\": []}\n",
    "\n",
    "for state in agg_user_list:\n",
    "    cur_states = path3 + state + \"//\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year = cur_states + year + \"//\"\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file = cur_year + file\n",
    "            data = open(cur_file, \"r\")\n",
    "\n",
    "            C = json.load(data)\n",
    "\n",
    "            try:\n",
    "                for i in C[\"data\"][\"usersByDevice\"]:\n",
    "                    brand = i[\"brand\"]\n",
    "                    count = i[\"count\"]\n",
    "                    percentage = i[\"percentage\"]\n",
    "                    columns3[\"Brands\"].append(brand)\n",
    "                    columns3[\"Transaction_count\"].append(count)\n",
    "                    columns3[\"Percentage\"].append(percentage)\n",
    "                    columns3[\"States\"].append(state)\n",
    "                    columns3[\"Years\"].append(year)\n",
    "                    columns3[\"Quarter\"].append(int(file.strip(\".json\"))) \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "aggre_user=pd.DataFrame(columns3)\n",
    "\n",
    "aggre_user[\"States\"]=aggre_user[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar' )\n",
    "aggre_user[\"States\"]=aggre_user[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_user[\"States\"]=aggre_user[\"States\"].str.title()\n",
    "aggre_user[\"States\"]=aggre_user[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggre_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_transaction\n",
    "\n",
    "path4=\"C://Users//aashi//Desktop//YoutubeProject//Phonepe//pulse//data//map//transaction//hover//country//india//state//\"\n",
    "map_tran_list = os.listdir(path4)\n",
    "\n",
    "\n",
    "columns4 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Districts\": [], \"Transaction_count\": [], \"Transaction_amount\": []}\n",
    "\n",
    "for state in map_tran_list:\n",
    "    cur_states = path4 + state + \"//\"\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in map_year_list:\n",
    "        cur_year = cur_states + year + \"//\"\n",
    "        map_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in map_file_list:\n",
    "            cur_file = cur_year + file\n",
    "            data = open(cur_file, \"r\")\n",
    "\n",
    "            D = json.load(data)\n",
    "            \n",
    "            for i in D[\"data\"][\"hoverDataList\"]:\n",
    "                    name = i[\"name\"]\n",
    "                    count = i[\"metric\"][0][\"count\"]\n",
    "                    amount = i[\"metric\"][0][\"amount\"]\n",
    "                    columns4[\"Districts\"].append(name)\n",
    "                    columns4[\"Transaction_count\"].append(count)\n",
    "                    columns4[\"Transaction_amount\"].append(amount)\n",
    "                    columns4[\"States\"].append(state)\n",
    "                    columns4[\"Years\"].append(year)\n",
    "                    columns4[\"Quarter\"].append(int(file.strip(\".json\"))) \n",
    "\n",
    "map_tran=pd.DataFrame(columns4)\n",
    "\n",
    "map_tran[\"States\"]=map_tran[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar' )\n",
    "map_tran[\"States\"]=map_tran[\"States\"].str.replace(\"-\",\" \")\n",
    "map_tran[\"States\"]=map_tran[\"States\"].str.title()\n",
    "map_tran[\"States\"]=map_tran[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#map_user\n",
    "path5 = \"C://Users//aashi//Desktop//YoutubeProject//Phonepe//pulse//data//map//user//hover//country//india//state//\"\n",
    "\n",
    "\n",
    "map_user_list = os.listdir(path5)\n",
    "\n",
    "\n",
    "columns5 = {\n",
    "    \"States\": [],\n",
    "    \"Years\": [],\n",
    "    \"Quarter\": [],\n",
    "    \"Districts\": [],\n",
    "    \"RegisteredUsers\": [],\n",
    "    \"AppOpens\": []\n",
    "}\n",
    "\n",
    "\n",
    "for state in map_user_list:\n",
    "    \n",
    "    cur_states = os.path.join(path5, state) + \"//\"\n",
    "    \n",
    "    map_year_list = os.listdir(cur_states)\n",
    "\n",
    "    \n",
    "    for year in map_year_list:\n",
    "    \n",
    "        cur_year = os.path.join(cur_states, year) + \"//\"\n",
    "        \n",
    "        map_file_list = os.listdir(cur_year)\n",
    "\n",
    "        \n",
    "        for file in map_file_list:\n",
    "            \n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "        \n",
    "            with open(cur_file, \"r\") as data:\n",
    "                \n",
    "                E = json.load(data)\n",
    "                \n",
    "                \n",
    "                for district, data in E[\"data\"][\"hoverData\"].items():\n",
    "                    \n",
    "                    registeredUsers = data[\"registeredUsers\"]\n",
    "                    appOpens = data[\"appOpens\"]\n",
    "                    \n",
    "                    \n",
    "                    columns5[\"Districts\"].append(district)\n",
    "                    columns5[\"RegisteredUsers\"].append(registeredUsers)\n",
    "                    columns5[\"AppOpens\"].append(appOpens)\n",
    "                    columns5[\"States\"].append(state)\n",
    "                    columns5[\"Years\"].append(year)\n",
    "                    columns5[\"Quarter\"].append(int(file.strip(\".json\"))) \n",
    "\n",
    "\n",
    "map_user = pd.DataFrame(columns5)\n",
    "\n",
    "\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"-\", \" \")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.title()\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu', 'Dadra and Nagar Haveli and Daman and Diu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_insurance\n",
    "\n",
    "path6 = \"C://Users//aashi//Desktop//YoutubeProject//Phonepe//pulse//data//map//insurance//hover//country//india//state//\"\n",
    "map_insur_list = os.listdir(path6)\n",
    "\n",
    "columns6 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Districts\": [], \"Transaction_count\": [],\n",
    "            \"Transaction_amount\": []}\n",
    "\n",
    "for state in map_insur_list:\n",
    "    cur_states = path6 + state + \"//\"\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in map_year_list:\n",
    "        cur_year = cur_states + year + \"//\"\n",
    "        map_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in map_file_list:\n",
    "            cur_file = cur_year + file\n",
    "            with open(cur_file, \"r\") as data:\n",
    "                E = json.load(data)\n",
    "\n",
    "                for i in E[\"data\"][\"hoverDataList\"]:\n",
    "                    name = i[\"name\"]\n",
    "                    count = i[\"metric\"][0][\"count\"]\n",
    "                    amount = i[\"metric\"][0][\"amount\"]\n",
    "                    columns6[\"Districts\"].append(name)\n",
    "                    columns6[\"Transaction_count\"].append(count)\n",
    "                    columns6[\"Transaction_amount\"].append(amount)\n",
    "                    columns6[\"States\"].append(state)\n",
    "                    columns6[\"Years\"].append(year)\n",
    "                    columns6[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_insurance=pd.DataFrame(columns6)\n",
    "\n",
    "map_insurance[\"States\"]=map_insurance[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar' )\n",
    "map_insurance[\"States\"]=map_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "map_insurance[\"States\"]=map_insurance[\"States\"].str.title()\n",
    "map_insurance[\"States\"]=map_insurance[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_insurance\n",
    "\n",
    "path7=\"C://Users//aashi//Desktop//YoutubeProject//Phonepe//pulse//data//top//insurance//country//india//state//\"\n",
    "top_insur_list=os.listdir(path7)\n",
    "\n",
    "columns7 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Pincodes\": [], \"Transaction_count\": [], \"Transaction_amount\": []}\n",
    "\n",
    "for state in top_insur_list:\n",
    "    cur_states = path7 + state + \"//\"\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in map_year_list:\n",
    "        cur_year = cur_states + year + \"//\"\n",
    "        map_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in map_file_list:\n",
    "            cur_file = cur_year + file\n",
    "            data = open(cur_file, \"r\")\n",
    "\n",
    "            F = json.load(data)\n",
    "            \n",
    "            for i in F[\"data\"][\"pincodes\"]:\n",
    "                entityname = i[\"entityName\"]\n",
    "                count = i[\"metric\"][\"count\"]\n",
    "                amount = i[\"metric\"][\"amount\"]\n",
    "                columns7[\"Pincodes\"].append(entityname)\n",
    "                columns7[\"Transaction_count\"].append(count)\n",
    "                columns7[\"Transaction_amount\"].append(amount)\n",
    "                columns7[\"States\"].append(state)\n",
    "                columns7[\"Years\"].append(year)\n",
    "                columns7[\"Quarter\"].append(int(file.strip(\".json\"))) \n",
    "\n",
    "top_insurance=pd.DataFrame(columns7)\n",
    "\n",
    "top_insurance[\"States\"]=top_insurance[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar' )\n",
    "top_insurance[\"States\"]=top_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "top_insurance[\"States\"]=top_insurance[\"States\"].str.title()\n",
    "top_insurance[\"States\"]=top_insurance[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_transaction\n",
    "\n",
    "path8=\"C://Users//aashi//Desktop//YoutubeProject//Phonepe//pulse//data//top//transaction//country//india//state//\"\n",
    "top_tran_list=os.listdir(path8)\n",
    "\n",
    "columns8 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Pincodes\": [], \"Transaction_count\": [], \"Transaction_amount\": []}\n",
    "\n",
    "for state in top_tran_list:\n",
    "    cur_states = path8 + state + \"//\"\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in map_year_list:\n",
    "        cur_year = cur_states + year + \"//\"\n",
    "        map_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in map_file_list:\n",
    "            cur_file = cur_year + file\n",
    "            data = open(cur_file, \"r\")\n",
    "\n",
    "            G = json.load(data)\n",
    "            \n",
    "            for i in G[\"data\"][\"pincodes\"]:\n",
    "                entityname = i[\"entityName\"]\n",
    "                count = i[\"metric\"][\"count\"]\n",
    "                amount = i[\"metric\"][\"amount\"]\n",
    "                columns8[\"Pincodes\"].append(entityname)\n",
    "                columns8[\"Transaction_count\"].append(count)\n",
    "                columns8[\"Transaction_amount\"].append(amount)\n",
    "                columns8[\"States\"].append(state)\n",
    "                columns8[\"Years\"].append(year)\n",
    "                columns8[\"Quarter\"].append(int(file.strip(\".json\"))) \n",
    "\n",
    "top_transaction=pd.DataFrame(columns8)\n",
    "\n",
    "top_transaction[\"States\"]=top_transaction[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar' )\n",
    "top_transaction[\"States\"]=top_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "top_transaction[\"States\"]=top_transaction[\"States\"].str.title()\n",
    "top_transaction[\"States\"]=top_transaction[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_user\n",
    "\n",
    "path9=\"C://Users//aashi//Desktop//YoutubeProject//Phonepe//pulse//data//top//user//country//india//state//\"\n",
    "top_user_list=os.listdir(path9)\n",
    "\n",
    "columns9 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Pincodes\": [], \"RegisteredUsers\": []}\n",
    "\n",
    "for state in top_user_list:\n",
    "    cur_states = path9 + state + \"//\"\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in map_year_list:\n",
    "        cur_year = cur_states + year + \"//\"\n",
    "        map_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in map_file_list:\n",
    "            cur_file = cur_year + file\n",
    "            data = open(cur_file, \"r\")\n",
    "\n",
    "            H = json.load(data)\n",
    "            \n",
    "            for i in H[\"data\"][\"pincodes\"]:\n",
    "                entityname = i[\"name\"]\n",
    "                registeredusers = i[\"registeredUsers\"]\n",
    "                columns9[\"Pincodes\"].append(entityname)\n",
    "                columns9[\"RegisteredUsers\"].append(registeredusers)\n",
    "                columns9[\"States\"].append(state)\n",
    "                columns9[\"Years\"].append(year)\n",
    "                columns9[\"Quarter\"].append(int(file.strip(\".json\"))) \n",
    "\n",
    "top_user=pd.DataFrame(columns9)\n",
    "\n",
    "\n",
    "top_user[\"States\"]=top_user[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar' )\n",
    "top_user[\"States\"]=top_user[\"States\"].str.replace(\"-\",\" \")\n",
    "top_user[\"States\"]=top_user[\"States\"].str.title()\n",
    "top_user[\"States\"]=top_user[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Creation\n",
    "#sql connection\n",
    "\n",
    "mydb=psycopg2.connect(host=\"localhost\",\n",
    "                      user=\"postgres\",\n",
    "                      port=\"5432\",\n",
    "                      database=\"phonepe_data\",\n",
    "                      password=\"suhana22\")\n",
    "cursor=mydb.cursor()\n",
    "\n",
    "#aggregated_insurance_table\n",
    "create_query_1='''CREATE TABLE if not exists aggregated_insurance(States varchar(255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Transaction_type varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_1)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_1='''INSERT INTO aggregated_insurance(States, Years, Quarter, Transaction_type,\n",
    "                                                      Transaction_count,\n",
    "                                                      Transaction_amount)\n",
    "                                                      \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "data= aggre_insurance.values.tolist()\n",
    "cursor.executemany(insert_query_1,data)\n",
    "mydb.commit()\n",
    "\n",
    "#aggregated_transaction_table\n",
    "create_query_2='''CREATE TABLE if not exists aggregated_transaction(States varchar(255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Transaction_type varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_2)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_2='''INSERT INTO aggregated_transaction(States, Years, Quarter, Transaction_type,\n",
    "                                                      Transaction_count,\n",
    "                                                      Transaction_amount)\n",
    "                                                      \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "data= aggre_transaction.values.tolist()\n",
    "cursor.executemany(insert_query_2,data)\n",
    "mydb.commit()\n",
    "\n",
    "#aggregated_user_table\n",
    "create_query_3='''CREATE TABLE if not exists aggregated_user(States varchar(255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Brands varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Percentage float)'''\n",
    "cursor.execute(create_query_3)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_3='''INSERT INTO aggregated_user(States, Years, Quarter, Brands,\n",
    "                                                      Transaction_count,\n",
    "                                                      Percentage)\n",
    "                                                      \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "data= aggre_user.values.tolist()\n",
    "cursor.executemany(insert_query_3,data)\n",
    "mydb.commit()\n",
    "\n",
    "#map_insurance_table\n",
    "create_query_4='''CREATE TABLE if not exists map_insurance(States varchar(255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    District varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_4)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_4='''INSERT INTO map_insurance(States, Years, Quarter, District,\n",
    "                                                      Transaction_count,\n",
    "                                                      Transaction_amount)\n",
    "                                                      \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "data= map_insurance.values.tolist()\n",
    "cursor.executemany(insert_query_4,data)\n",
    "mydb.commit()\n",
    "\n",
    "#map_transaction_table\n",
    "create_query_5='''CREATE TABLE if not exists map_transaction(States varchar(255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    District varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_5)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_5='''INSERT INTO map_transaction(States, Years, Quarter, District,\n",
    "                                                      Transaction_count,\n",
    "                                                      Transaction_amount)\n",
    "                                                      \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "data= map_tran.values.tolist()\n",
    "cursor.executemany(insert_query_5,data)\n",
    "mydb.commit()\n",
    "\n",
    "#map_user_table\n",
    "create_query_6='''CREATE TABLE if not exists map_user(States varchar(255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Districts varchar(255),\n",
    "                                                    RegisteredUsers bigint,\n",
    "                                                    AppOpens bigint)'''\n",
    "cursor.execute(create_query_6)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_6='''INSERT INTO map_user(States, Years, Quarter, Districts,\n",
    "                                                      RegisteredUsers,\n",
    "                                                      AppOpens)\n",
    "                                                      \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "data= map_user.values.tolist()\n",
    "cursor.executemany(insert_query_6,data)\n",
    "mydb.commit()\n",
    "\n",
    "#top_insurance_table\n",
    "create_query_7='''CREATE TABLE if not exists top_insurance(States varchar(255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Pincodes varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_7)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_7='''INSERT INTO top_insurance(States, Years, Quarter, Pincodes,\n",
    "                                                      Transaction_count,\n",
    "                                                      Transaction_amount)\n",
    "                                                      \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "data= top_insurance.values.tolist()\n",
    "cursor.executemany(insert_query_7,data)\n",
    "mydb.commit()\n",
    "\n",
    "#top_transaction_table\n",
    "create_query_8='''CREATE TABLE if not exists top_transaction(States varchar(255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Pincodes varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_8)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_8='''INSERT INTO top_transaction(States, Years, Quarter, Pincodes,\n",
    "                                                      Transaction_count,\n",
    "                                                      Transaction_amount)\n",
    "                                                      \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "data= top_transaction.values.tolist()\n",
    "cursor.executemany(insert_query_8,data)\n",
    "mydb.commit()\n",
    "\n",
    "#top_user_table\n",
    "create_query_9='''CREATE TABLE if not exists top_user(States varchar(255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Pincodes varchar(255),\n",
    "                                                    RegisteredUsers bigint\n",
    "                                                    )'''\n",
    "cursor.execute(create_query_9)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_9='''INSERT INTO top_user(States, Years, Quarter, Pincodes,\n",
    "                                                      RegisteredUsers)\n",
    "                                                      \n",
    "                                                      \n",
    "                                                       values(%s,%s,%s,%s,%s)'''\n",
    "data= top_user.values.tolist()\n",
    "cursor.executemany(insert_query_9,data)\n",
    "mydb.commit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
